% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenizer.R
\name{tokenize}
\alias{tokenize}
\title{An R wrapper for Jagger's tokenizer}
\usage{
tokenize(input, model_path = NULL, keep = NULL, concat = TRUE)
}
\arguments{
\item{input}{an input.}

\item{model_path}{a path to the model.}

\item{keep}{a vector of POS(s) to keep. Default is \code{NULL}.}

\item{concat}{logical. If TRUE, the function returns a concatenated string. Default is \code{TRUE}.}
}
\value{
a list.
}
\description{
An R wrapper for Jagger's tokenizer
}
\examples{
\dontrun{
 texts <- read.csv(
   "https://raw.githubusercontent.com/koheiw/workshop-IJTA/master/data/asahi.csv",
   sep = "\t", stringsAsFactors = FALSE, encoding = "UTF-8"
 )
 tokenize(texts$head)
}
}
